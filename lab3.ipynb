{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Constituency parsing with CKY\n",
    "\n",
    "### Natural Language Processing, 2020\n",
    "\n",
    "\n",
    "The grammatical structure of a sentence can be represented with a Context Free Grammar (CFG). When we additionally assign probabilities to the rules of the CFG we get a PCFG: a _Probabilistic_ CFG. \n",
    "\n",
    "Given a sufficiently expressive PCFG (one that holds enough rules) we can parse new sentences using the Cocke–Kasami–Younger (CKY) algorithm. You can use this algorithm in three ways: to find the set of all the possible parses $p$ of a sentence $s$ under a PCFG $G$; to find the probability of the sentence by summing up the probabilities of these parses; or to find the parse $p^{*}$ of the highest probability.\n",
    "\n",
    "\n",
    "### Tasks\n",
    "1. In this notebook you will learn how to represent a PCFG in an object-oriented manner as a collection of python classes. These classes are already defined for you. Read them through thoroughly and make sure that you understand them well. You have to use them in task 2.\n",
    "\n",
    "2. Implement the CKY algorithm to find the most probable parse $p^{*}$ for a sentence. Your implementation will follow the psuedo-code that is given in both the lecture slides, and Jurafsky and Martin.\n",
    "\n",
    "The reference for this notebook is chapters 13 and 14 of [Jurafsky and Martin](https://web.stanford.edu/~jurafsky/slp3/) (both in the 2nd and 3rd edition) and the slides from week 3.\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "### Rules\n",
    "* The lab exercises should be made in **groups of two people**.\n",
    "\n",
    "* The assignment should submitted to **Blackboard** as `.ipynb`. Only **one submission per group**. See Blackboard for date of submission. \n",
    "\n",
    "* The **filename** should be `lab2_id1_id2.ipynb`.\n",
    "\n",
    "* The notebook is graded on a scale of **0-100**. The number of points for each question is indicated in parantheses. \n",
    "\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should **write your code and answers in this iPython Notebook** (see http://ipython.org/notebook.html for reference material). If you have problems, please contact your teaching assistant.\n",
    "\n",
    "* Use only **one cell for code** and **one cell for markdown** answers!    \n",
    "\n",
    "    * Put all code in the cell with the `# YOUR CODE HERE` comment.\n",
    "    \n",
    "    * For theoretical questions, put your solution in the YOUR ANSWER HERE cell.\n",
    "    \n",
    "* Test your code and **make sure we can run your notebook**\n",
    "\n",
    "* For some sections in this notebook, you will need to have the Natural Language Toolkit ([NLTK](http://www.nltk.org/)) installed. We will use a feature of the NLTK toolkit that lets you draw constituency parses. Details for download can be found here: http://www.nltk.org/install.html.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PCFG\n",
    "\n",
    "In this lab we will show you a way to represent a **PCFG** using python objects. We will introduce the following classes:\n",
    "\n",
    "* Symbol\n",
    "    * Terminal\n",
    "    * Nonterminal\n",
    "* Rule\n",
    "\n",
    "At first glance, this might seem like a lot of work. But, hopefully, by the time you get to implementing CKY you will be confinced of the benefits of these constructions.\n",
    "\n",
    "## Symbol\n",
    "\n",
    "Recall that:\n",
    "* **Terminal** symbols are the words of the sentence: _I, ate, salad, the_ etc.\n",
    "* **Nonterminal** symbols are the syntactic categories of the various constituents: _S, NP, VP, Det_ etc.\n",
    "\n",
    "In our representation, `Symbol` is going to be a container class. The classes `Terminal` and `Nonterminal` will *inherit* from the `Symbol` class and will hence both become a type of symbol. The classes themselves are effectively a container for the underlying python strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbol:\n",
    "    \"\"\"\n",
    "    A symbol in a grammar.\n",
    "    This class will be used as parent class for Terminal, Nonterminal.\n",
    "    This way both will be a type of Symbol.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Terminal(Symbol):\n",
    "    \"\"\"\n",
    "    Terminal symbols are words in a vocabulary\n",
    "    \n",
    "    E.g. 'I', 'ate', 'salad', 'the'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol: str):\n",
    "        assert type(symbol) is str, 'A Terminal takes a python string, got %s' % type(symbol)\n",
    "        self._symbol = symbol\n",
    "\n",
    "    def is_terminal(self):\n",
    "        return True\n",
    "\n",
    "    def is_nonterminal(self):\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"'%s'\" % self._symbol\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Terminal(%r)' % self._symbol\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self._symbol)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"The length of the underlying python string\"\"\"\n",
    "        return len(self._symbol)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return type(self) == type(other) and self._symbol == other._symbol\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not (self == other)\n",
    "    \n",
    "    @property\n",
    "    def obj(self):\n",
    "        \"\"\"Returns the underlying python string\"\"\"\n",
    "        return self._symbol\n",
    "\n",
    "\n",
    "class Nonterminal(Symbol):\n",
    "    \"\"\"\n",
    "    Nonterminal symbols are the grammatical classes in a grammar.\n",
    "    \n",
    "    E.g. S, NP, VP, N, Det, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol: str):\n",
    "        assert type(symbol) is str, 'A Nonterminal takes a python string, got %s' % type(symbol)\n",
    "        self._symbol = symbol\n",
    "\n",
    "    def is_terminal(self):\n",
    "        return False\n",
    "    \n",
    "    def is_nonterminal(self):\n",
    "        return True\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"[%s]\" % self._symbol\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Nonterminal(%r)' % self._symbol\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self._symbol)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"The length of the underlying python string\"\"\"\n",
    "        return len(self._symbol)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return type(self) == type(other) and self._symbol == other._symbol\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not (self == other)\n",
    "    \n",
    "    @property\n",
    "    def obj(self):\n",
    "        \"\"\"Returns the underlying python string\"\"\"\n",
    "        return self._symbol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the classes by initializing some terminal and nonterminal symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = Terminal('dog')\n",
    "the = Terminal('the')\n",
    "walks = Terminal('walks')\n",
    "\n",
    "S = Nonterminal('S')\n",
    "NP = Nonterminal('NP')\n",
    "NP_prime = Nonterminal('NP')\n",
    "VP = Nonterminal('VP')\n",
    "V = Nonterminal('V')\n",
    "N = Nonterminal('N')\n",
    "Det = Nonterminal('Det')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods `__eq__` and `__ne__` make it possible to compare our objects using standard Python syntax. But more importantly: compare in the way that we are interested in, namely whether the underlying representation is the same.\n",
    "\n",
    "To see the difference, try commenting out the method `__eq__` in the class above, and notice the different result of the equality test `NP==NP_prime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dog'\n",
      "[NP]\n",
      "\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(dog)\n",
    "print(NP)\n",
    "print()\n",
    "print(NP==Det)\n",
    "print(NP!=Det)\n",
    "print(NP==NP)\n",
    "print(NP==NP_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference between calling `print(NP)` and simply calling `NP`. The first is taken care of by the method `__str__` and the second by the method `__repr__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Terminal('dog')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily check if our symbol is a terminal or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.is_terminal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NP.is_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the method `__hash__` makes our object *hashable*, and hence usable in a datastructure like a dictionary. \n",
    "\n",
    "Try commenting out this method above in the class and then retry constructing the dictionary: notice the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Nonterminal('NP'): 1, Nonterminal('S'): 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {NP: 1, S: 2}\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "In a PCFG a **rule** looks something like this \n",
    "\n",
    "$$NP \\to Det\\;N,$$\n",
    "\n",
    "with a corresponding probability, for example $1.0$ if we lived in a world where all noun phrases had this grammatical structure.\n",
    "\n",
    "In our representation, `Rule` will be an object made of a left-hand side (`lhs`) symbol, a sequence of right-hand side symbols (`rhs`) and a probability `prob`. \n",
    "\n",
    "If we use the above defined symbols, we can call\n",
    "\n",
    "    rule = Rule(NP, [Det, N], 1.0).\n",
    "   \n",
    "This will construct an instance called `rule` which represent the rule above\n",
    "\n",
    "    [NP] -> [Det] [N] (1.0).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "\n",
    "    def __init__(self, lhs, rhs, prob):\n",
    "        \"\"\"\n",
    "        Constructs a Rule.\n",
    "        A Rule takes a LHS symbol and a list/tuple of RHS symbols.\n",
    "\n",
    "        :param lhs: the LHS nonterminal\n",
    "        :param rhs: a sequence of RHS symbols (terminal or nonterminal)\n",
    "        :param prob: probability of the rule\n",
    "        \"\"\"\n",
    "\n",
    "        assert isinstance(lhs, Symbol), 'LHS must be an instance of Symbol'\n",
    "        assert len(rhs) > 0, 'If you want an empty RHS, use an epsilon Terminal EPS'\n",
    "        assert all(isinstance(s, Symbol) for s in rhs), 'RHS must be a sequence of Symbol objects'\n",
    "        self._lhs = lhs\n",
    "        self._rhs = tuple(rhs)\n",
    "        self._prob = prob\n",
    "\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self._lhs == other._lhs and self._rhs == other._rhs and self._prob == other._prob\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not (self == other)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self._lhs, self._rhs, self._prob))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '%s -> %s (%s)' % (self._lhs,\n",
    "                ' '.join(str(sym) for sym in self._rhs),\n",
    "                self.prob)\n",
    "\n",
    "    def is_binary(self):\n",
    "        \"\"\"True if Rule is binary: A -> B C\"\"\"\n",
    "        return len(self._rhs) == 2\n",
    "    \n",
    "    def is_unary(self):\n",
    "        \"\"\"True if Rule is unary: A -> w\"\"\"\n",
    "        return len(self._rhs) == 1\n",
    "    \n",
    "    @property\n",
    "    def lhs(self):\n",
    "        \"\"\"Returns the lhs of the rule\"\"\"\n",
    "        return self._lhs\n",
    "\n",
    "    @property\n",
    "    def rhs(self):\n",
    "        \"\"\"Returns the rhs of the rule\"\"\"\n",
    "        return self._rhs\n",
    "\n",
    "    @property\n",
    "    def prob(self):\n",
    "        \"\"\"Returns the probability of the rule\"\"\"\n",
    "        return self._prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with `Terminal` and `Nonterminal` you can print an instance of `Rule`, you can access its attributes, and you can hash rules with containers such as dict and set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S] -> [NP] [VP] (1.0)\n",
      "[NP] -> [Det] [N] (1.0)\n",
      "[N] -> 'dog' (1.0)\n",
      "[Det] -> 'the' (1.0)\n"
     ]
    }
   ],
   "source": [
    "r1 = Rule(S, [NP, VP], 1.0)\n",
    "r2 = Rule(NP, [Det, N], 1.0)\n",
    "r3 = Rule(N, [dog], 1.0)\n",
    "r4 = Rule(Det, [the], 1.0)\n",
    "r5 = Rule(VP, [walks], 1.0)\n",
    "\n",
    "print(r1)\n",
    "print(r2)\n",
    "print(r3)\n",
    "print(r4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(r1.prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 in set([r1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{[S] -> [NP] [VP] (1.0): 1, [NP] -> [Det] [N] (1.0): 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {r1: 1, r2: 2}\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar\n",
    "\n",
    "A `PCFG` class is a container for `Rules`. The `Rules` are stored in the `PCFG` in such a way that they can be accesed easily in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCFG(object):\n",
    "    \"\"\"\n",
    "    Constructs a PCFG.\n",
    "    A PCFG stores a list of rules that can be accessed in various ways.\n",
    "    \n",
    "    :param rules: an optional list of rules to initialize the grammar with\n",
    "    \"\"\"\n",
    "    def __init__(self, rules=[]):\n",
    "        self._rules = []\n",
    "        self._rules_by_lhs = defaultdict(list)\n",
    "        self._terminals = set()\n",
    "        self._nonterminals = set()\n",
    "        for rule in rules:\n",
    "            self.add(rule)\n",
    "\n",
    "    def add(self, rule):\n",
    "        \"\"\"Adds a rule to the grammar\"\"\"\n",
    "        if not rule in self._rules:\n",
    "            self._rules.append(rule)\n",
    "            self._rules_by_lhs[rule.lhs].append(rule)\n",
    "            self._nonterminals.add(rule.lhs)\n",
    "            for s in rule.rhs:\n",
    "                if s.is_terminal():\n",
    "                    self._terminals.add(s)\n",
    "                else:\n",
    "                    self._nonterminals.add(s)\n",
    "\n",
    "    def update(self, rules):\n",
    "        \"\"\"Add a list of rules to the grammar\"\"\"\n",
    "        for rule in rules:\n",
    "            self.add(rule)\n",
    "\n",
    "    @property\n",
    "    def nonterminals(self):\n",
    "        \"\"\"The list of nonterminal symbols in the grammar\"\"\"\n",
    "        return self._nonterminals\n",
    "\n",
    "    @property\n",
    "    def terminals(self):\n",
    "        \"\"\"The list of terminal symbols in the grammar\"\"\"\n",
    "        return self._terminals\n",
    "    \n",
    "    @property\n",
    "    def rules(self):\n",
    "        \"\"\"The list of rules in the grammar\"\"\"\n",
    "        return self._rules\n",
    "    \n",
    "    @property\n",
    "    def binary_rules(self):\n",
    "        \"\"\"The list of binary rules in the grammar\"\"\"\n",
    "        return [rule for rule in self._rules if rule.is_binary()]\n",
    "    \n",
    "    @property\n",
    "    def unary_rules(self):\n",
    "        \"\"\"The list of unary rules in the grammar\"\"\"\n",
    "        return [rule for rule in self._rules if rule.is_unary()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._rules)\n",
    "\n",
    "    def __getitem__(self, lhs):\n",
    "        return self._rules_by_lhs.get(lhs, frozenset())\n",
    "\n",
    "    def get(self, lhs, default=frozenset()):\n",
    "        \"\"\"The list of rules whose LHS is the given symbol lhs\"\"\"\n",
    "        return self._rules_by_lhs.get(lhs, frozenset())\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterator over rules (in arbitrary order)\"\"\"\n",
    "        return iter(self._rules)\n",
    "\n",
    "    def iteritems(self):\n",
    "        \"\"\"Iterator over pairs of the kind (LHS, rules rewriting LHS)\"\"\"\n",
    "        return self._rules_by_lhs.items()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Prints the grammar line by line\"\"\"\n",
    "        lines = []\n",
    "        for lhs, rules in self.iteritems():\n",
    "            for rule in rules:\n",
    "                lines.append(str(rule))\n",
    "        return '\\n'.join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = PCFG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add rules individually with `add`, or as a list with `update`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add(r1)\n",
    "G.update([r2,r3,r4,r5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can print the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S] -> [NP] [VP] (1.0)\n",
      "[NP] -> [Det] [N] (1.0)\n",
      "[N] -> 'dog' (1.0)\n",
      "[Det] -> 'the' (1.0)\n",
      "[VP] -> 'walks' (1.0)\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the set of rewrite rules for a certain LHS symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[S] -> [NP] [VP] (1.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.get(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[N]\n",
      "'dog'\n",
      "[Det]\n",
      "'the'\n",
      "[VP]\n",
      "'walks'\n"
     ]
    }
   ],
   "source": [
    "for i in G.unary_rules:\n",
    "    print(i.lhs)\n",
    "    print(i.rhs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the'\n",
      "'dog'\n",
      "'walks'\n"
     ]
    }
   ],
   "source": [
    "for i in G.terminals:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[NP] -> [Det] [N] (1.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.get(NP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate through rules in the grammar.\n",
    "\n",
    "Note that the following is basically counting how many rules we have in the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for r in G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which can also be done in a more efficient way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the set of terminals and nonterminals of the grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Nonterminal('S'), Nonterminal('Det'), Nonterminal('NP'), Nonterminal('N'), Nonterminal('VP')}\n"
     ]
    }
   ],
   "source": [
    "print(G.nonterminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Terminal('the'), Terminal('dog'), Terminal('walks')}\n"
     ]
    }
   ],
   "source": [
    "print(G.terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S in G.nonterminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S]\n",
      "[Det]\n",
      "[NP]\n",
      "[N]\n",
      "[VP]\n"
     ]
    }
   ],
   "source": [
    "for s in G.nonterminals:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog in G.terminals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can easily access all the binary rules and all the unary rules in the grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[N] -> 'dog' (1.0), [Det] -> 'the' (1.0), [VP] -> 'walks' (1.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.unary_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[S] -> [NP] [VP] (1.0), [NP] -> [Det] [N] (1.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.binary_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "For the following sections you will need to have the Natural Language Toolkit ([NLTK](http://www.nltk.org/)) installed. We will use a feature of the NLTK toolkit that lets you draw constituency parses. Details for download can be found here: http://www.nltk.org/install.html.\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "\n",
    "# Visualizing a tree\n",
    "\n",
    "For the sake of legacy let's reiterate an age-old NLP schtick, the well-known example of structural ambiguity from the Groucho Marx movie, [Animal Crackers](https://youtu.be/FZUfhfHbjE4?t=1m33s) (1930):\n",
    "\n",
    "> One morning I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\n",
    "\n",
    "Let's take a closer look at the ambiguity in the phrase: _I shot an elephant in my pajamas_. The ambiguity is caused by the fact that the sentence has two competing parses represented in:\n",
    "\n",
    "    (S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\n",
    "\n",
    "and\n",
    "\n",
    "    (S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\n",
    "\n",
    "\n",
    "We can write these parses down as strings and then let NLTK turn them into trees using the NLTK `Tree` class. (See http://www.nltk.org/api/nltk.html#nltk.tree.Tree as reference for this class, if you want to know more.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse1 = \"(S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\"\n",
    "parse2 = \"(S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\"\n",
    "\n",
    "pajamas1 = Tree.fromstring(parse1)\n",
    "pajamas2 = Tree.fromstring(parse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then *pretty-print* these trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S                                       \n",
      "  ___|______________                          \n",
      " |                  VP                       \n",
      " |         _________|__________               \n",
      " |        VP                   PP            \n",
      " |    ____|___              ___|___           \n",
      " |   |        NP           |       NP        \n",
      " |   |     ___|_____       |    ___|_____     \n",
      " NP  V   Det        N      P  Det        N   \n",
      " |   |    |         |      |   |         |    \n",
      " I  shot  an     elephant  in  my     pajamas\n",
      "\n",
      "     S                                       \n",
      "  ___|__________                              \n",
      " |              VP                           \n",
      " |    __________|______                       \n",
      " |   |                 NP                    \n",
      " |   |     ____________|___                   \n",
      " |   |    |                NP                \n",
      " |   |    |      __________|___               \n",
      " |   |    |     |              PP            \n",
      " |   |    |     |       _______|___           \n",
      " |   |    |     |      |           NP        \n",
      " |   |    |     |      |        ___|_____     \n",
      " NP  V   Det    N      P      Det        N   \n",
      " |   |    |     |      |       |         |    \n",
      " I  shot  an elephant  in      my     pajamas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pajamas1.pretty_print()\n",
    "pajamas2.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing with CKY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stick with this sentence for the rest of this lab. We will use CKY to find the 'best' parse for this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the sentence into a list\n",
    "sentence = \"I shot an elephant in my pajamas\".split()\n",
    "# The length of the sentence\n",
    "num_words = len(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PCFG for this sentence can be found in the file `groucho-grammar.txt`. We read this in with the function `read_grammar_rules`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grammar_rules(istream):\n",
    "    \"\"\"Reads grammar rules formatted as 'LHS ||| RHS ||| PROB'.\"\"\"\n",
    "    for line in istream:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        fields = line.split('|||')\n",
    "        if len(fields) != 3:\n",
    "            raise ValueError('I expected 3 fields: %s', fields)\n",
    "        lhs = fields[0].strip()\n",
    "\n",
    "        if lhs[0] == '[':\n",
    "            lhs = Nonterminal(lhs[1:-1])\n",
    "        else:\n",
    "            lhs = Terminal(lhs)\n",
    "        rhs = fields[1].strip().split()\n",
    "        new_rhs = []\n",
    "        for r in rhs:\n",
    "            if r[0] == '[':\n",
    "                r = Nonterminal(r[1:-1])\n",
    "            else:\n",
    "                r = Terminal(r)\n",
    "            new_rhs.append(r)\n",
    "\n",
    "        prob = float(fields[2].strip())\n",
    "        yield Rule(lhs, new_rhs, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grammar:\n",
      " [S] -> [NP] [VP] (1.0)\n",
      "[PP] -> [P] [NP] (1.0)\n",
      "[NP] -> [Det] [N] (0.2)\n",
      "[NP] -> [Det] [NP] (0.3)\n",
      "[NP] -> [N] [PP] (0.3)\n",
      "[NP] -> 'I' (0.2)\n",
      "[VP] -> [V] [NP] (0.4)\n",
      "[VP] -> [VP] [PP] (0.6)\n",
      "[Det] -> 'an' (0.6)\n",
      "[Det] -> 'my' (0.4)\n",
      "[N] -> 'elephant' (0.5)\n",
      "[N] -> 'pajamas' (0.5)\n",
      "[V] -> 'shot' (1.0)\n",
      "[P] -> 'in' (1.0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the grammar\n",
    "istream = open('groucho-grammar-1.txt')\n",
    "grammar = PCFG(read_grammar_rules(istream))\n",
    "print(\"The grammar:\\n\", grammar, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the following two dictionaries: `nonterminal2index` mapping from nonterminals to integers (indices); and its inverse, an `index2nonterminal` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Nonterminal('S'): 0, Nonterminal('Det'): 1, Nonterminal('V'): 2, Nonterminal('NP'): 3, Nonterminal('PP'): 4, Nonterminal('P'): 5, Nonterminal('VP'): 6, Nonterminal('N'): 7}\n",
      "{0: Nonterminal('S'), 1: Nonterminal('Det'), 2: Nonterminal('V'), 3: Nonterminal('NP'), 4: Nonterminal('PP'), 5: Nonterminal('P'), 6: Nonterminal('VP'), 7: Nonterminal('N')}\n"
     ]
    }
   ],
   "source": [
    "num_nonterminals = len(grammar.nonterminals)\n",
    "\n",
    "# Make a nonterminal2index and a index2nonterminal dictionary\n",
    "n2i = defaultdict(lambda: len(n2i))\n",
    "i2n = dict()\n",
    "for A in grammar.nonterminals:\n",
    "    i2n[n2i[A]] = A\n",
    "\n",
    "# Stop defaultdict behavior of n2i\n",
    "n2i = dict(n2i)\n",
    "\n",
    "print(n2i)\n",
    "print(i2n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The charts\n",
    "\n",
    "Now we are ready to introduce the chart datastructures. We need a chart to store the **scores** and a chart to store the **backpointers**.\n",
    "\n",
    "Both of these will be 3-dimensional numpy arrays: one named `score` (also named `table` in J&M) holding the probabilities of intermediate results; one named `back` to store the backpointers in. We will use the following indexing convention for these charts:\n",
    "\n",
    "* Format for the chart holding the **scores**: \n",
    "\n",
    "         score[A][begin][end] = probability   (naming as in slides)\n",
    "         table[A][i][j] = probability         (naming as in J&M) \n",
    "         \n",
    "* Format for the chart holding the **backpointers**:\n",
    "\n",
    "         back[A][begin][end] = (split,B,C)    (naming as in slides)\n",
    "         back[A][i][j] = (k,B,C)              (naming as in J&M) \n",
    "         \n",
    "\n",
    "This indexing convention is convenient for printing. See what happens when we print `back` below: we get `num_nonterminal` slices, each a numpy array of shape `[n_words+1, n_words+1]`. This is easier to read than the format `table[i][j][A]`.\n",
    "\n",
    "**[Note]** Here we pretended `A` is both the nonterminal as well as the index. In actual fact, in our implementation `A` will be the nonterminal and the index for `A` will be `n2i[A]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show you what we mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A numpy array zeros\n",
    "score = np.zeros((num_nonterminals,\n",
    "                  num_words + 1, \n",
    "                  num_words + 1))\n",
    "\n",
    "# A numpy array that can store arbitrary data (we set dtype to object)\n",
    "back = np.zeros((num_nonterminals,\n",
    "                 num_words + 1, \n",
    "                 num_words + 1), dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following illustrates the way you will use the `back` chart. In this example, your parser recognized that the words between 0 and 2 form an NP and the words between 2 and the end of the sentence form a VP (and nothing else yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 0, (2, Nonterminal('NP'), Nonterminal('VP'))],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustration of the backpointer array\n",
    "back[n2i[S]][0][-1] = (2,NP,VP) \n",
    "back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. (80 points)\n",
    "\n",
    "Implement the **CKY** algorithm. Follow the pseudo-code given in the lecture-slides (or alternatively in J&M). The code must comply to the following:\n",
    "\n",
    "* The function `cky` takes a sentence (list of words) a grammar (an instance of PCFG) and a n2i nonterminals2index dictionary.\n",
    "* The function `cky` returns the filled-in score-chart and backpointer-chart, following the format established above.\n",
    "\n",
    "**[Hint]** This is the moment to make good use of the methods of the classes `PCFG`, `Rule`, `Nonterminal`, and `Terminal`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cky(sentence, grammar, n2i):\n",
    "    \"\"\"\n",
    "    The CKY algorithm.\n",
    "    \n",
    "    Follow the pseudocode from the slides (or J&M).\n",
    "    \n",
    "    :param sentence: a list of words\n",
    "    :param grammar: an instance of the class PCFG\n",
    "    :param n2i: a dictionary mapping from Nonterminals to indices\n",
    "    :return score: the filled in scores chart\n",
    "    :return back: the filled in backpointers chart \n",
    "    \"\"\"\n",
    "    num_words = len(sentence)\n",
    "    print(num_words)\n",
    "    num_nonterminals = len(grammar.nonterminals)\n",
    "    \n",
    "    # A numpy array to store the scores of intermediate parses\n",
    "    score = np.zeros((num_nonterminals,\n",
    "                  num_words + 1, \n",
    "                  num_words + 1))\n",
    "\n",
    "    # A numpy array to store the backpointers\n",
    "    back = np.zeros((num_nonterminals,\n",
    "                     num_words + 1, \n",
    "                     num_words + 1), dtype=object)\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    for i in range(0,num_words):\n",
    "        for n in grammar.nonterminals:\n",
    "            for r in grammar.unary_rules:\n",
    "                if (r.lhs == n and r.rhs[0] == Terminal(sentence[i])):\n",
    "                    #print(i,i+1)\n",
    "                    score[n2i[n]][i][i+1] = r.prob\n",
    "    for span in range(1,num_words+1):\n",
    "        for begin in range(0,num_words+1 -span):\n",
    "            end = span+begin\n",
    "            for split in range(begin+1,end):\n",
    "                #print(begin,split,end)\n",
    "                for r in grammar.binary_rules:\n",
    "                    N = r.lhs\n",
    "                    P = r.rhs[0]\n",
    "                    Q = r.rhs[1]\n",
    "                    prob = score[n2i[P]][begin][split] * score[n2i[Q]][split][end]*r.prob\n",
    "                    if prob > score[n2i[N]][begin][end]:\n",
    "                        score[n2i[N]][begin][end] = prob\n",
    "                        back[n2i[N]][begin][end] = (split,P,Q)\n",
    "    return score, back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.800e-03 0.000e+00 0.000e+00\n",
      "   1.152e-04]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]\n",
      "\n",
      " [[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 6.000e-01 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.000e-01\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]\n",
      "\n",
      " [[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]\n",
      "\n",
      " [[0.000e+00 2.000e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 6.000e-02 0.000e+00 0.000e+00\n",
      "   1.080e-03]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   6.000e-03]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   4.000e-02]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]\n",
      "\n",
      " [[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   4.000e-02]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]\n",
      "\n",
      " [[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]\n",
      "\n",
      " [[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.400e-02 0.000e+00 0.000e+00\n",
      "   5.760e-04]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]\n",
      "\n",
      " [[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 5.000e-01 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   5.000e-01]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00]]]\n",
      "[[[0 0 0 0 (1, Nonterminal('NP'), Nonterminal('VP')) 0 0\n",
      "   (1, Nonterminal('NP'), Nonterminal('VP'))]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 (3, Nonterminal('Det'), Nonterminal('N')) 0 0\n",
      "   (3, Nonterminal('Det'), Nonterminal('NP'))]\n",
      "  [0 0 0 0 0 0 0 (4, Nonterminal('N'), Nonterminal('PP'))]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 (6, Nonterminal('Det'), Nonterminal('N'))]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 (5, Nonterminal('P'), Nonterminal('NP'))]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 (2, Nonterminal('V'), Nonterminal('NP')) 0 0\n",
      "   (4, Nonterminal('VP'), Nonterminal('PP'))]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# Run CKY\n",
    "score, back = cky(sentence, grammar, n2i)\n",
    "print(score)\n",
    "print(back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your CKY\n",
    "\n",
    "Use the code in the following two cell to check your `cky` implementation.\n",
    "\n",
    "Take the Nonterminal `S` to inspect your filled in score and backpointer charts. **Leave the code in this cell unchanged.** We will use this to evaluate the corectness your cky function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole slice for nonterminal S:\n",
      "[[0.        0.        0.        0.        0.0048    0.        0.\n",
      "  0.0001152]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.       ]] \n",
      "\n",
      "The score in cell (S, 0, num_words), which is the probability of the best parse:\n",
      "0.00011520000000000004 \n",
      "\n",
      "The backpointer in cell (S, 0, num_words):\n",
      "(1, Nonterminal('NP'), Nonterminal('VP')) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Don't change the code in this cell. ###\n",
    "\n",
    "S = Nonterminal('S')\n",
    "\n",
    "print('The whole slice for nonterminal S:')\n",
    "print(score[n2i[S]], \"\\n\")\n",
    "\n",
    "print('The score in cell (S, 0, num_words), which is the probability of the best parse:')\n",
    "print(score[n2i[S]][0][num_words], \"\\n\")\n",
    "\n",
    "print('The backpointer in cell (S, 0, num_words):')\n",
    "print(back[n2i[S]][0][num_words], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. (20 points)\n",
    "\n",
    "Write the function `build_tree` that reconstructs the parse from the backpointer table. This is the function that is called in the return statement of the pseudo-code in Jurafsky and Martin.\n",
    "\n",
    "**[Note]** This is a challenging exercise! And we have no pseudocode for you here: you must come up with your own implementation. On the other hand, it will also constitute just the last 20 points of your your grade, so don't worry too much if can't finish it. If you finished exercise 1 you already have an 8 for this lab!\n",
    "\n",
    "Here is some additional advice:\n",
    " \n",
    "* Use recursion - that is write your function in a recursive way. \n",
    "\n",
    "    * What is the base case? Hint: $A \\to w$.\n",
    "    * What is the recursive case? Hint: $A \\to B\\; C$.\n",
    "    \n",
    "    \n",
    "* Use the additional clas `Span` that we introduce below for the symbols in your recovered rules.\n",
    "    \n",
    "    * Read the documentation in this class for its usage.\n",
    "    \n",
    "    \n",
    "* If you want to use the function `make_nltk_tree` that we provide (and that turns a `derivation` into an NLTK tree so that you can draw it) your function must return the **list of rules in derivation ordered depth-first**. \n",
    "    \n",
    "    * If you write your function recursively this should happen automatically.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class will be very useful in your solution for the function `build_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Span(Symbol):\n",
    "    \"\"\"\n",
    "    A Span indicates that symbol was recognized between begin and end.\n",
    "    \n",
    "    Example:\n",
    "        Span(Terminal('the'), 0, 1)\n",
    "            This means: we found 'the' in the sentence between 0 and 1\n",
    "        Span(Nonterminal('NP'), 4, 8) represents NP:4-8\n",
    "            This means: we found an NP that covers the part of the sentence between 4 and 8\n",
    "    \n",
    "    Thus, Span holds a Terminal or a Nonterminal and wraps it between two integers. \n",
    "    This makes it possible to distinguish between two instances of the same rule in the derrivation.\n",
    "    Example:\n",
    "        We can find that the rule NP -> Det N is use twice in the parse derrivation. But that in the first\n",
    "        case it spans \"an elephant\" and in the second case it spans \"my pajamas\". We want to distinguis these. \n",
    "        So: \"an elephant\" is covered by [NP]:2-4 -> [Det]:2-3 [N]:3-4\n",
    "            \"my pajamas\" is covered by [NP]:5-7 -> [Det]:5-6 [N]:6-7\n",
    "        \n",
    "    Internally, we represent spans with tuples of the kind (symbol, start, end).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol, start, end):\n",
    "        assert isinstance(symbol, Symbol), 'A span takes an instance of Symbol, got %s' % type(symbol)\n",
    "        self._symbol = symbol\n",
    "        self._start = start\n",
    "        self._end = end\n",
    "\n",
    "    def is_terminal(self):\n",
    "        # a span delegates this to an underlying symbol\n",
    "        return self._symbol.is_terminal()\n",
    "\n",
    "    def root(self):\n",
    "        # Spans are hierarchical symbols, thus we delegate\n",
    "        return self._symbol.root()\n",
    "\n",
    "    def obj(self):\n",
    "        \"\"\"The underlying python tuple (Symbol, start, end)\"\"\"\n",
    "        return (self._symbol, self._start, self._end)\n",
    "\n",
    "    def translate(self, target):\n",
    "        return Span(self._symbol.translate(target), self._start, self._end)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Prints Symbol with span if Symbol is Nonterminal else without (purely aesthetic distinction)\"\"\"\n",
    "        if self.is_terminal():\n",
    "            return \"%s\" % (self._symbol)\n",
    "        else: \n",
    "            return \"%s:%s-%s\" % (self._symbol, self._start, self._end)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Span(%r, %r, %r)' % (self._symbol, self._start, self._end)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self._symbol, self._start, self._end))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return type(self) == type(other) and self._symbol == other._symbol and self._start == other._start and self._end == other._end\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not (self == other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of `Span`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dog'\n",
      "[NP]:2-4 -> [Det]:2-3 [NP]:3-4 (None)\n"
     ]
    }
   ],
   "source": [
    "span_S = Span(S, 0, 10)\n",
    "span_S = Span(dog, 4, 5)\n",
    "print(span_S)\n",
    "\n",
    "spanned_rule = Rule(Span(NP, 2, 4), [Span(Det, 2, 3), Span(NP, 3, 4)], prob=None)\n",
    "print(spanned_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your final derivation should look like this:\n",
    "\n",
    "![derivation-illustration](derivation-illustration.png)\n",
    "\n",
    "(Note that the rule probabilities are set to `None`. These are not saved in the backpointer chart so cannot be retrieved at the recovering stage. They also don't matter at this point, so you can set them to `None`.)\n",
    "\n",
    "If you give this derivation to the function`make_nltk_tree` and then let NLTK draw it, then you get this tree:\n",
    "\n",
    "![span-illustration](span-illustration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "def build_tree(back, sentence, root, n2i):\n",
    "    \"\"\"\n",
    "    Reconstruct the viterbi parse from a filled-in backpointer chart.\n",
    "    \n",
    "    It returns a list called derivation which hols the rules that. If you \n",
    "    want to use the function make_nltk_tree you must make sure that the\n",
    "    \n",
    "    :param back: a backpointer chart of shape [num_nonterminals, num_words+1, num_words+1]\n",
    "    :param sentence: a list of words\n",
    "    :param root: the root symbol of the tree: Nonterminal('S')\n",
    "    :param n2i: the dictionary mapping from Nonterminals to indices\n",
    "    :return derivation: a derivation: a list of Rules with Span symbols that generate the Viterbi tree. \n",
    "                        If you want to draw them with the function that we provide, then this list \n",
    "                        should be ordered depth first!\n",
    "    \"\"\"\n",
    "    derivation = []\n",
    "    num_words = len(sentence)\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    #first step we create a LIFO queue to handle depth the depth first situation & dynamic behavior\n",
    "    q = queue.LifoQueue()\n",
    "    q.put([S, 0, num_words]) #we are placing in the queue lists that contain the symbol, its start and end\n",
    "    while q.empty() == False:\n",
    "        it = q.get()\n",
    "        symb = it[0]\n",
    "        start = it[1]\n",
    "        end = it[2]\n",
    "        it = Span(symb,start,end)\n",
    "        #Terminal situation\n",
    "        if start+1 == end:\n",
    "            derivation.append(Rule(it, [Terminal(sentence[end-1])], prob = None))\n",
    "        else: #Non terminal symbols\n",
    "            helper = back[n2i[symb]][start][end]\n",
    "            zero = Span(helper[1],start, helper[0])\n",
    "            one = Span(helper[2], helper[0], end)\n",
    "            derivation.append(Rule(it,[zero,one],prob = None))\n",
    "            #reverse order because we use LIFO queue and we want to go depth first\n",
    "            q.put([helper[2], helper[0], end])\n",
    "            q.put([helper[1],start, helper[0]])\n",
    "    \n",
    "    return derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get your derivation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[S]:0-7 -> [NP]:0-1 [VP]:1-7 (None),\n",
       " [NP]:0-1 -> 'I' (None),\n",
       " [VP]:1-7 -> [VP]:1-4 [PP]:4-7 (None),\n",
       " [VP]:1-4 -> [V]:1-2 [NP]:2-4 (None),\n",
       " [V]:1-2 -> 'shot' (None),\n",
       " [NP]:2-4 -> [Det]:2-3 [N]:3-4 (None),\n",
       " [Det]:2-3 -> 'an' (None),\n",
       " [N]:3-4 -> 'elephant' (None),\n",
       " [PP]:4-7 -> [P]:4-5 [NP]:5-7 (None),\n",
       " [P]:4-5 -> 'in' (None),\n",
       " [NP]:5-7 -> [Det]:5-6 [N]:6-7 (None),\n",
       " [Det]:5-6 -> 'my' (None),\n",
       " [N]:6-7 -> 'pajamas' (None)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivation = build_tree(back, sentence, S, n2i)\n",
    "derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the derivation into an NLTK tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [S]:0-7                                                                   \n",
      "    ________|___________________________                                            \n",
      "   |                                 [VP]:1-7                                      \n",
      "   |                  __________________|__________________                         \n",
      "   |              [VP]:1-4                              [PP]:4-7                   \n",
      "   |         ________|________                     ________|________                \n",
      "   |        |              [NP]:2-4               |              [NP]:5-7          \n",
      "   |        |         ________|_________          |         ________|_________      \n",
      "[NP]:0-1 [V]:1-2 [Det]:2-3           [N]:3-4   [P]:4-5 [Det]:5-6           [N]:6-7 \n",
      "   |        |        |                  |         |        |                  |     \n",
      "  'I'     'shot'    'an'            'elephant'   'in'     'my'            'pajamas'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_nltk_tree(derivation):\n",
    "    \"\"\"\n",
    "    Return a NLTK Tree object based on the derivation\n",
    "    (list or tuple of Rules)\n",
    "    \"\"\"\n",
    "    d = defaultdict(None, ((r.lhs, r.rhs) for r in derivation))\n",
    "\n",
    "    def make_tree(lhs):\n",
    "        return Tree(str(lhs), (str(child) if child not in d else make_tree(child) for child in d[lhs]))\n",
    "\n",
    "    return make_tree(derivation[0].lhs)\n",
    "\n",
    "tree = make_nltk_tree(derivation)\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "\n",
    "Congratulations, you have made it to the end of the lab.\n",
    "\n",
    "**Make sure all your cells are executed so that all your answers are there. Then, continue if you're interested!**\n",
    "\n",
    "----\n",
    "\n",
    "# Optional\n",
    "\n",
    "If you managed to get your entire CKY-parser working and have an appetite for more, it might be fun to try it on some more sentences and grammars. Give the grammars below a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Groucho-grammar\n",
    "\n",
    "If you change the probabilities in the grammar, you'll get a different parse as the most likely one. Compare `groucho-grammar-1.txt` with `groucho-grammar-2.txt` and spot the difference in probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The man with the telescope\n",
    "\n",
    "Another ambiguous sentence:\n",
    "\n",
    "> I saw the man on the hill with the telescope.\n",
    "\n",
    "A grammar for this sentence is specified in the file `telescope-grammar.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
